{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratoria 9: BERT i atencja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D48rgmQSB0B6"
   },
   "source": [
    "## Atencja dekodera względem enkodera\n",
    "\n",
    "Poniżej znajdują się dwie macierze, `encoder_states` oraz `decoder_states` reprezentujące stan warstwy ukrytej po przetworzeniu każdego slowa z enkodera i dekodera. Pojedynczy stan warstwy ukrytej zawiera embedding o dlugosci = 3. W enkoderze mamy 4 stany warstwy ukrytej RNNów, gdyż przetwarzamy sekwencję 4 tokenów.\n",
    "\n",
    "W dekoderze mamy 5 tokenów, które powinny być wygenerowane z sekwencji przetwarzanej (en)koderem.\n",
    "\n",
    "Zadanie polega na:\n",
    "a) Obliczniu podobieństwa wszystkich embeddingów z dekodera (queries) względem wszystkich embeddingów kolejnych stanów (en)kodera (keys) [pamiętajcie, że macierze potrafią w transponowanie. W `NumPy` macierz transponujemy za pomocą `macierz.T`]\n",
    "\n",
    "b) Na utworzonej macierzy podobieństwa należy wykonać softmax (zaimportowany z scipy). Uwaga:  pamiętajcie, żeby aplikować softmax w dobrym wymiarze. Wszystkie stany ukryte enkodera powinny zostac zasoftmaksowane względem zadanego stanu dekodera, nie odwrotnie. W scipy, funkcja softmax zawiera argument axis, który może pomóc.\n",
    "\n",
    "c) Należy wykorzystać macierz atencji z kroku b) i `encoder_states` do wygenerowania macierzy zawierającej wektory kontekstu dla każdego tokenu z dekodera.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vQsum9iYATge"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:\n",
      "[[  4.806   2.376   7.762   1.129]\n",
      " [ 12.164 -12.645  73.935   3.636]\n",
      " [ 27.79  -16.962  94.002   7.137]\n",
      " [ 18.702  -5.184  42.616   4.501]\n",
      " [ 64.38   49.86   56.21   14.45 ]]\n",
      "\n",
      "Weights:\n",
      "[[4.91780633e-02 4.32948093e-03 9.45248312e-01 1.24414389e-03]\n",
      " [1.49003187e-27 2.50486173e-38 1.00000000e+00 2.94803216e-31]\n",
      " [1.75587568e-29 6.44090821e-49 1.00000000e+00 1.88369172e-38]\n",
      " [4.11416552e-11 1.74069934e-21 1.00000000e+00 2.79811669e-17]\n",
      " [9.99716568e-01 4.94220792e-07 2.82937800e-04 2.06801368e-22]]\n",
      "\n",
      "Attention:\n",
      "[[ 9.69108631  0.35799187  0.59163688]\n",
      " [10.2         0.2         0.3       ]\n",
      " [10.2         0.2         0.3       ]\n",
      " [10.2         0.2         0.3       ]\n",
      " [ 1.20254471  3.39909302  5.59850122]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "\n",
    "# scipy.special.softmax(x, axis=None)\n",
    "\n",
    "encoder_states = np.array(\n",
    "    [[1.2, 3.4, 5.6],    # embedding z warstwy ukrytej enkodera w kroku 1\n",
    "    [-2.3, 0.2, 7.2],   # embedding z warstwy ukrytej enkodera w kroku 2\n",
    "    [10.2, 0.2, 0.3],   # embedding z warstwy ukrytej enkodera w kroku 3\n",
    "    [0.4, 0.7, 1.2]]    # embedding z warstwy ukrytej enkodera w kroku 4 (koniec sekwencji)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "decoder_states = np.array(\n",
    "    [[0.74, 0.23, 0.56],  # embedding z warstwy ukrytej dekodera w kroku 1\n",
    "    [7.23, 0.12, 0.55],  # embedding z warstwy ukrytej dekodera w kroku 2\n",
    "    [9.12, 4.23, 0.44],  # embedding z warstwy ukrytej dekodera w kroku 3\n",
    "    [4.1, 3.23, 0.5],    # embedding z warstwy ukrytej dekodera w kroku 4\n",
    "    [5.2, 3.1, 8.5]]     # embedding z warstwy ukrytej dekodera w kroku 5\n",
    ")\n",
    "\n",
    "scores = decoder_states @ encoder_states.T\n",
    "print(f\"Scores:\\n{scores}\")\n",
    "weights = softmax(scores, axis=1)\n",
    "print(f\"\\nWeights:\\n{weights}\")\n",
    "attention = weights @ encoder_states\n",
    "print(f\"\\nAttention:\\n{attention}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9220arNHo1V"
   },
   "source": [
    "## Tokenizacja tekstu wykorzystując tokenizator BERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "uMLn-hE8L6Zh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'i', \"'\", 've', 'bought', 'a', 'new', 'gp', '##u', 'last', 'year', 'it', 'was', 'ge', '##force', 'rt', '##x', '406', '##0', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "text_to_tokenize = \"I've bought a new GPU last year it was GeForce RTX 4060\"\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokens = tokenizer.encode(text_to_tokenize)\n",
    "\n",
    "print(tokenizer.convert_ids_to_tokens(tokens))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Zadania10-2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
