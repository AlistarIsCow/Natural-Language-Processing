{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przygotowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "1\n",
      "Przed paddingiem. Średnia długość wektora: 238.71364; odchylenie std: 176.49367364852034\n",
      "Po paddingu. Średnia długość wektora: 500.0; odchylenie std: 0.0\n",
      "W zbiorze testowym jest 12500 elementów o pozytywnym sentymencie i 12500 elementów o negatywnym. Sentyment pozytywny stanowi 50.0% zbioru.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.datasets import imdb\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "\n",
    "print(x_train[0]) # wyświetlenie wektora cech dla pierwszej recenzji\n",
    "print(y_train[0]) # wyświetlenie etykiety (1 = sentyment pozytywny; 0 = sentyment negatywny)\n",
    "\n",
    "average_x_len = np.mean([len(x) for x in x_train]) # średnia liczba cech w wektorach x_train\n",
    "stddev_x_len = np.std([len(x) for x in x_train]) # odchylenie standardowe dla x_train\n",
    "\n",
    "x_train = pad_sequences(x_train, 500) # padding do 500 tokenów\n",
    "x_test = pad_sequences(x_test, 500)   # padding do 500 tokenów\n",
    "\n",
    "padded_average_x_len = np.mean([len(x) for x in x_train]) # średnia liczba cech w wektorach x_train po paddingu\n",
    "padded_stddev_x_len = np.std([len(x) for x in x_train]) # odchylenie standardowe po x_train po paddingu\n",
    "\n",
    "counts = dict(zip(*np.unique(y_test, return_counts=True)))\n",
    "count_positive = counts[1]\n",
    "count_negative = counts[0]\n",
    "\n",
    "print(\"Przed paddingiem. Średnia długość wektora: {ave_len}; odchylenie std: {std_dev}\".format(\n",
    "    ave_len=average_x_len, std_dev=stddev_x_len))\n",
    "\n",
    "print(\"Po paddingu. Średnia długość wektora: {ave_len}; odchylenie std: {std_dev}\".format(\n",
    "    ave_len=padded_average_x_len, std_dev=padded_stddev_x_len))\n",
    "\n",
    "print(\"W zbiorze testowym jest {pos} elementów o pozytywnym sentymencie i {neg} elementów o negatywnym. Sentyment pozytywny stanowi {percentage}% zbioru.\".format(\n",
    "pos=count_positive, neg=count_negative, percentage = 100.0*(count_positive)/(count_positive + count_negative)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przykładowa prosta sieć w Keras.\n",
    "Sieć dwuwarstwowa o:\n",
    "<ol>\n",
    "<li>100 wejśc</li>\n",
    "<li>warstwa ukryta z 64 neuronami o aktywacji ReLU</li>\n",
    "<li>warstwa wyjściowa z 1 neuronem o aktywacji sigmoidalnej</li>\n",
    "</ol>\n",
    "\n",
    "$ReLU(x) = max(0, x)$, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kapi1\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5080 - loss: 158.3256 - val_accuracy: 0.5037 - val_loss: 3.3967\n",
      "Epoch 2/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5038 - loss: 2.0898 - val_accuracy: 0.5012 - val_loss: 1.4270\n",
      "Epoch 3/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5049 - loss: 0.9581 - val_accuracy: 0.4981 - val_loss: 1.0881\n",
      "Epoch 4/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5045 - loss: 0.7838 - val_accuracy: 0.5051 - val_loss: 1.0086\n",
      "Epoch 5/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5021 - loss: 0.7376 - val_accuracy: 0.5028 - val_loss: 1.0096\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - accuracy: 0.5058 - loss: 1.0275\n",
      "Trafność klasyfikacji to: 50.279998779296875%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Embedding, LSTM, GRU, Conv1D, MaxPooling1D\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, input_dim=500, activation='relu')) # dodanie warstwy Dense - wszystkie wejścia połączone są w sposób każdy z każdym\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', # klasyfikację z dwiema etykietami -> 'binary_crossentropy'\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy']) # wybór miary oceny\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test)) # nauka modelu\n",
    "\n",
    "loss, accuracy = model.evaluate(x_test, y_test, batch_size=128) # ostateczna ewaluacja wyuczonego modelu\n",
    "print(\"Trafność klasyfikacji to: {acc}%\".format(acc=accuracy*100)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wykorzystanie embeddingów w sieci feed forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kapi1\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.6534 - loss: 0.5854 - val_accuracy: 0.8640 - val_loss: 0.3152\n",
      "Epoch 2/2\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9376 - loss: 0.1737 - val_accuracy: 0.8668 - val_loss: 0.3194\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 969us/step - accuracy: 0.8672 - loss: 0.3210\n",
      "Trafność klasyfikacji to: 86.67600154876709%\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(10000, output_dim=32, input_length=500))\n",
    "model.add(Flatten()) #zamiana macierzy na wektor\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid')) #wygenerowanie prawdopodobieństwa pozytywnego sentymentu\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=2, batch_size=128)\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"Trafność klasyfikacji to: {acc}%\".format(acc=accuracy*100)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architektury rekurencyjne (LSTM i GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 201ms/step - accuracy: 0.6519 - loss: 0.6271 - val_accuracy: 0.8330 - val_loss: 0.3847\n",
      "Epoch 2/2\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 195ms/step - accuracy: 0.8446 - loss: 0.3708 - val_accuracy: 0.8228 - val_loss: 0.4032\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - accuracy: 0.8219 - loss: 0.4046\n",
      "Trafność klasyfikacji to: 82.28399753570557%\n",
      "Czas treningu: 80.15641784667969\n",
      "Epoch 1/2\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 217ms/step - accuracy: 0.5405 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 2/2\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 218ms/step - accuracy: 0.4963 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 0.5073 - loss: nan\n",
      "Trafność klasyfikacji to: 50.0%\n",
      "Czas treningu: 88.03914904594421\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(10000, 32, input_length=500))\n",
    "model.add(LSTM(32, dropout = 0.2, recurrent_dropout = 0.2)) # warstwa sieci rekurencyjnej LSTM\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "start_time = time.time()\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=2, batch_size=128)\n",
    "end_time = time.time()\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"Trafność klasyfikacji to: {acc}%\".format(acc=accuracy*100)) \n",
    "print(\"Czas treningu: {t}\".format(t=end_time - start_time))\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(10000, 32, input_length=500))\n",
    "model.add(GRU(32, dropout = 0.2, recurrent_dropout = 0.2)) # warstwa sieci rekurencyjnej GRU\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "start_time = time.time()\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=2, batch_size=128)\n",
    "end_time = time.time()\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"Trafność klasyfikacji to: {acc}%\".format(acc=accuracy*100)) \n",
    "print(\"Czas treningu: {t}\".format(t=end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architektury konwolucyjne (Conv1D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.6406 - loss: 0.5815 - val_accuracy: 0.8839 - val_loss: 0.2767\n",
      "Epoch 2/2\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - accuracy: 0.9266 - loss: 0.1933 - val_accuracy: 0.8891 - val_loss: 0.2737\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8888 - loss: 0.2734\n",
      "Trafność klasyfikacji to: 88.90799880027771%\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(10000, 32, input_length=500))\n",
    "model.add(Conv1D(32, 3, padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=2, batch_size=128)\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"Trafność klasyfikacji to: {acc}%\".format(acc=accuracy*100)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
